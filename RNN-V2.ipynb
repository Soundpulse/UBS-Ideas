{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Code modified from https://www.tensorflow.org/tutorials/structured_data/time_series#single_step_model*\n",
    "### *Modified by Soundpulse :D*\n",
    "\n",
    "## TODO:\n",
    "\n",
    "- Use Grid Search for better hyperparameters\n",
    "- transform the predicted data back to the original axis\n",
    "- Ensembling with other predicting architectures (Expotential Smoothing, Regression, KNN Regressor etc.)\n",
    "- Extra: Dimensionality Reduction on the dataset? ðŸ¤”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Science Accelerator Credentials \n",
    "RESOURCE_ENDPOINT = \"https://dsa-stg-edp-api.fr-nonprod.aws.thomsonreuters.com/data/historical-pricing/beta1/views/summaries/\" \n",
    "access_token = 'tUn7ZD2ZsW9jKiFpoS56ua2g3hnLaUEE8A1nE6cQ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ric = 'JPY=' # put the RIC of the asset you want to retrieve data\n",
    "\n",
    "requestData = {\n",
    "    'interval': 'P1D',\n",
    "    'start': '2016-11-01',\n",
    "    'end': '2019-06-30',\n",
    "    #\"fields\": 'TRDPRC_1' # Uncomment this line if you wish to specify which fields to be returned, e.g. TRDPRC_1 is an available field for AAPL.O\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data access successful\n"
     ]
    }
   ],
   "source": [
    "def get_data_request(url, requestData):\n",
    "    \"\"\"\n",
    "    HTTP GET request to Refinitiv API\n",
    "    \n",
    "    There is more information in the returned dict (i.e. json) object from the API, we store the data in a DataFrame.\n",
    "    \n",
    "    :param url: str, the url of the API endpoint\n",
    "    :param requestData: dict, contains user-defined variables\n",
    "    :return: DataFrame, containing the historical pricing data. \n",
    "        Returned field list order and content can vary depending on the exchange / instrument.\n",
    "        Therefore returned data must be treated using appropriate parsing techniques.\n",
    "    \"\"\"\n",
    "    dResp = requests.get(url, headers = {'X-api-key': access_token}, params = requestData);       \n",
    "\n",
    "    if dResp.status_code != 200:\n",
    "        raise ValueError(\"Unable to get data. Code %s, Message: %s\" % (dResp.status_code, dResp.text));\n",
    "    else:\n",
    "        print(\"Data access successful\")\n",
    "        jResp = json.loads(dResp.text);\n",
    "        data = jResp[0]['data']\n",
    "        headers = jResp[0]['headers']  \n",
    "        names = [headers[x]['name'] for x in range(len(headers))]\n",
    "        df = pd.DataFrame(data, columns=names )\n",
    "        return df\n",
    "    \n",
    "resource_endpoint_ric = RESOURCE_ENDPOINT + ric  \n",
    "df = get_data_request(resource_endpoint_ric, requestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(694, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>BID</th>\n",
       "      <th>ASK</th>\n",
       "      <th>BID_HIGH_1</th>\n",
       "      <th>BID_LOW_1</th>\n",
       "      <th>OPEN_BID</th>\n",
       "      <th>MID_PRICE</th>\n",
       "      <th>NUM_BIDS</th>\n",
       "      <th>ASK_LOW_1</th>\n",
       "      <th>ASK_HIGH_1</th>\n",
       "      <th>...</th>\n",
       "      <th>ASIACL_BID</th>\n",
       "      <th>EUROP_BID</th>\n",
       "      <th>EURHI_BID</th>\n",
       "      <th>EURLO_BID</th>\n",
       "      <th>EURCL_BID</th>\n",
       "      <th>AMEROP_BID</th>\n",
       "      <th>AMERHI_BID</th>\n",
       "      <th>AMERLO_BID</th>\n",
       "      <th>AMERCL_BID</th>\n",
       "      <th>OPEN_ASK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-28</td>\n",
       "      <td>107.88</td>\n",
       "      <td>107.91</td>\n",
       "      <td>107.93</td>\n",
       "      <td>107.55</td>\n",
       "      <td>107.78</td>\n",
       "      <td>107.895</td>\n",
       "      <td>91894.0</td>\n",
       "      <td>107.57</td>\n",
       "      <td>107.96</td>\n",
       "      <td>...</td>\n",
       "      <td>107.64</td>\n",
       "      <td>107.63</td>\n",
       "      <td>107.85</td>\n",
       "      <td>107.58</td>\n",
       "      <td>107.84</td>\n",
       "      <td>107.66</td>\n",
       "      <td>107.93</td>\n",
       "      <td>107.62</td>\n",
       "      <td>107.88</td>\n",
       "      <td>107.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-06-27</td>\n",
       "      <td>107.78</td>\n",
       "      <td>107.81</td>\n",
       "      <td>108.15</td>\n",
       "      <td>107.63</td>\n",
       "      <td>107.78</td>\n",
       "      <td>107.795</td>\n",
       "      <td>94057.0</td>\n",
       "      <td>107.66</td>\n",
       "      <td>108.18</td>\n",
       "      <td>...</td>\n",
       "      <td>108.04</td>\n",
       "      <td>108.05</td>\n",
       "      <td>108.15</td>\n",
       "      <td>107.66</td>\n",
       "      <td>107.72</td>\n",
       "      <td>107.82</td>\n",
       "      <td>107.94</td>\n",
       "      <td>107.66</td>\n",
       "      <td>107.78</td>\n",
       "      <td>107.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-06-26</td>\n",
       "      <td>107.77</td>\n",
       "      <td>107.80</td>\n",
       "      <td>107.84</td>\n",
       "      <td>107.08</td>\n",
       "      <td>107.18</td>\n",
       "      <td>107.785</td>\n",
       "      <td>81259.0</td>\n",
       "      <td>107.11</td>\n",
       "      <td>107.87</td>\n",
       "      <td>...</td>\n",
       "      <td>107.46</td>\n",
       "      <td>107.47</td>\n",
       "      <td>107.75</td>\n",
       "      <td>107.35</td>\n",
       "      <td>107.63</td>\n",
       "      <td>107.67</td>\n",
       "      <td>107.84</td>\n",
       "      <td>107.58</td>\n",
       "      <td>107.77</td>\n",
       "      <td>107.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-25</td>\n",
       "      <td>107.17</td>\n",
       "      <td>107.20</td>\n",
       "      <td>107.40</td>\n",
       "      <td>106.77</td>\n",
       "      <td>107.29</td>\n",
       "      <td>107.185</td>\n",
       "      <td>98267.0</td>\n",
       "      <td>106.79</td>\n",
       "      <td>107.43</td>\n",
       "      <td>...</td>\n",
       "      <td>107.03</td>\n",
       "      <td>106.81</td>\n",
       "      <td>107.14</td>\n",
       "      <td>106.80</td>\n",
       "      <td>106.91</td>\n",
       "      <td>106.97</td>\n",
       "      <td>107.39</td>\n",
       "      <td>106.82</td>\n",
       "      <td>107.17</td>\n",
       "      <td>107.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-06-24</td>\n",
       "      <td>107.28</td>\n",
       "      <td>107.31</td>\n",
       "      <td>107.53</td>\n",
       "      <td>107.23</td>\n",
       "      <td>107.39</td>\n",
       "      <td>107.295</td>\n",
       "      <td>86297.0</td>\n",
       "      <td>107.26</td>\n",
       "      <td>107.55</td>\n",
       "      <td>...</td>\n",
       "      <td>107.39</td>\n",
       "      <td>107.42</td>\n",
       "      <td>107.53</td>\n",
       "      <td>107.23</td>\n",
       "      <td>107.35</td>\n",
       "      <td>107.29</td>\n",
       "      <td>107.53</td>\n",
       "      <td>107.23</td>\n",
       "      <td>107.28</td>\n",
       "      <td>107.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE     BID     ASK  BID_HIGH_1  BID_LOW_1  OPEN_BID  MID_PRICE  \\\n",
       "0  2019-06-28  107.88  107.91      107.93     107.55    107.78    107.895   \n",
       "1  2019-06-27  107.78  107.81      108.15     107.63    107.78    107.795   \n",
       "2  2019-06-26  107.77  107.80      107.84     107.08    107.18    107.785   \n",
       "3  2019-06-25  107.17  107.20      107.40     106.77    107.29    107.185   \n",
       "4  2019-06-24  107.28  107.31      107.53     107.23    107.39    107.295   \n",
       "\n",
       "   NUM_BIDS  ASK_LOW_1  ASK_HIGH_1  ...  ASIACL_BID  EUROP_BID  EURHI_BID  \\\n",
       "0   91894.0     107.57      107.96  ...      107.64     107.63     107.85   \n",
       "1   94057.0     107.66      108.18  ...      108.04     108.05     108.15   \n",
       "2   81259.0     107.11      107.87  ...      107.46     107.47     107.75   \n",
       "3   98267.0     106.79      107.43  ...      107.03     106.81     107.14   \n",
       "4   86297.0     107.26      107.55  ...      107.39     107.42     107.53   \n",
       "\n",
       "   EURLO_BID  EURCL_BID  AMEROP_BID  AMERHI_BID  AMERLO_BID  AMERCL_BID  \\\n",
       "0     107.58     107.84      107.66      107.93      107.62      107.88   \n",
       "1     107.66     107.72      107.82      107.94      107.66      107.78   \n",
       "2     107.35     107.63      107.67      107.84      107.58      107.77   \n",
       "3     106.80     106.91      106.97      107.39      106.82      107.17   \n",
       "4     107.23     107.35      107.29      107.53      107.23      107.28   \n",
       "\n",
       "   OPEN_ASK  \n",
       "0    107.81  \n",
       "1    107.81  \n",
       "2    107.21  \n",
       "3    107.30  \n",
       "4    107.40  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DATE'] = pd.to_datetime(df['DATE']).astype('O')\n",
    "df.set_index('DATE', inplace=True)\n",
    "\n",
    "df['dBid']= df.BID_HIGH_1 - df.BID_LOW_1\n",
    "df['AMER_dBid']= df.AMERHI_BID - df.AMERLO_BID\n",
    "df['ASIA_dBid']= df.ASIAHI_BID - df.ASIALO_BID\n",
    "df['EUR_dBid']= df.EURHI_BID - df.EURLO_BID\n",
    "\n",
    "df['OTC'] = df.AMERCL_BID.shift() - df.AMEROP_BID\n",
    "df['AMER_OTC'] = df.AMERCL_BID.shift() - df.AMEROP_BID\n",
    "df['ASIA_OTC'] = df.ASIACL_BID.shift() - df.ASIAOP_BID\n",
    "df['EUR_OTC'] = df.EURCL_BID.shift() - df.EUROP_BID\n",
    "\n",
    "df['FT'] = df.AMERCL_BID - df.AMEROP_BID\n",
    "df['AMER_FT'] = df.AMERCL_BID - df.AMEROP_BID\n",
    "df['ASIA_FT'] = df.ASIACL_BID - df.ASIAOP_BID\n",
    "df['EUR_FT'] = df.EURCL_BID - df.EUROP_BID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BID</th>\n",
       "      <th>BID_HIGH_1</th>\n",
       "      <th>BID_LOW_1</th>\n",
       "      <th>OPEN_BID</th>\n",
       "      <th>NUM_BIDS</th>\n",
       "      <th>ASIAOP_BID</th>\n",
       "      <th>ASIAHI_BID</th>\n",
       "      <th>ASIALO_BID</th>\n",
       "      <th>ASIACL_BID</th>\n",
       "      <th>EUROP_BID</th>\n",
       "      <th>...</th>\n",
       "      <th>ASIA_dBid</th>\n",
       "      <th>EUR_dBid</th>\n",
       "      <th>OTC</th>\n",
       "      <th>AMER_OTC</th>\n",
       "      <th>ASIA_OTC</th>\n",
       "      <th>EUR_OTC</th>\n",
       "      <th>FT</th>\n",
       "      <th>AMER_FT</th>\n",
       "      <th>ASIA_FT</th>\n",
       "      <th>EUR_FT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-06-28</th>\n",
       "      <td>-1.354560</td>\n",
       "      <td>-1.471352</td>\n",
       "      <td>-1.303735</td>\n",
       "      <td>-1.388737</td>\n",
       "      <td>-0.707884</td>\n",
       "      <td>-1.388733</td>\n",
       "      <td>-1.455779</td>\n",
       "      <td>-1.357381</td>\n",
       "      <td>-1.427498</td>\n",
       "      <td>-1.427070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.703278</td>\n",
       "      <td>-1.054196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552453</td>\n",
       "      <td>0.552453</td>\n",
       "      <td>-0.437472</td>\n",
       "      <td>0.506419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-27</th>\n",
       "      <td>-1.396251</td>\n",
       "      <td>-1.380715</td>\n",
       "      <td>-1.270578</td>\n",
       "      <td>-1.388737</td>\n",
       "      <td>-0.618119</td>\n",
       "      <td>-1.388733</td>\n",
       "      <td>-1.323379</td>\n",
       "      <td>-1.324542</td>\n",
       "      <td>-1.263411</td>\n",
       "      <td>-1.254421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093774</td>\n",
       "      <td>-0.332944</td>\n",
       "      <td>0.071864</td>\n",
       "      <td>0.071864</td>\n",
       "      <td>-0.231369</td>\n",
       "      <td>-0.337620</td>\n",
       "      <td>-0.123834</td>\n",
       "      <td>-0.123834</td>\n",
       "      <td>0.822916</td>\n",
       "      <td>-0.879180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-26</th>\n",
       "      <td>-1.400420</td>\n",
       "      <td>-1.508430</td>\n",
       "      <td>-1.498534</td>\n",
       "      <td>-1.638134</td>\n",
       "      <td>-1.149242</td>\n",
       "      <td>-1.638130</td>\n",
       "      <td>-1.592316</td>\n",
       "      <td>-1.550310</td>\n",
       "      <td>-1.501337</td>\n",
       "      <td>-1.492841</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.238331</td>\n",
       "      <td>-0.628002</td>\n",
       "      <td>0.147874</td>\n",
       "      <td>0.147874</td>\n",
       "      <td>1.387019</td>\n",
       "      <td>0.345029</td>\n",
       "      <td>0.240321</td>\n",
       "      <td>0.240321</td>\n",
       "      <td>0.885935</td>\n",
       "      <td>0.378123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-25</th>\n",
       "      <td>-1.650566</td>\n",
       "      <td>-1.689704</td>\n",
       "      <td>-1.627019</td>\n",
       "      <td>-1.592411</td>\n",
       "      <td>-0.443402</td>\n",
       "      <td>-1.592408</td>\n",
       "      <td>-1.633691</td>\n",
       "      <td>-1.677562</td>\n",
       "      <td>-1.677731</td>\n",
       "      <td>-1.764146</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459090</td>\n",
       "      <td>-0.824707</td>\n",
       "      <td>1.196813</td>\n",
       "      <td>1.196813</td>\n",
       "      <td>0.270332</td>\n",
       "      <td>1.190921</td>\n",
       "      <td>0.500431</td>\n",
       "      <td>0.500431</td>\n",
       "      <td>-0.815588</td>\n",
       "      <td>0.224167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-24</th>\n",
       "      <td>-1.604705</td>\n",
       "      <td>-1.636146</td>\n",
       "      <td>-1.436364</td>\n",
       "      <td>-1.550845</td>\n",
       "      <td>-0.940163</td>\n",
       "      <td>-1.550842</td>\n",
       "      <td>-1.600591</td>\n",
       "      <td>-1.476423</td>\n",
       "      <td>-1.530052</td>\n",
       "      <td>-1.513394</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.902541</td>\n",
       "      <td>-0.955843</td>\n",
       "      <td>-0.201772</td>\n",
       "      <td>-0.201772</td>\n",
       "      <td>-0.587414</td>\n",
       "      <td>-0.782826</td>\n",
       "      <td>-0.045800</td>\n",
       "      <td>-0.045800</td>\n",
       "      <td>0.003664</td>\n",
       "      <td>-0.212040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 BID  BID_HIGH_1  BID_LOW_1  OPEN_BID  NUM_BIDS  ASIAOP_BID  \\\n",
       "DATE                                                                          \n",
       "2019-06-28 -1.354560   -1.471352  -1.303735 -1.388737 -0.707884   -1.388733   \n",
       "2019-06-27 -1.396251   -1.380715  -1.270578 -1.388737 -0.618119   -1.388733   \n",
       "2019-06-26 -1.400420   -1.508430  -1.498534 -1.638134 -1.149242   -1.638130   \n",
       "2019-06-25 -1.650566   -1.689704  -1.627019 -1.592411 -0.443402   -1.592408   \n",
       "2019-06-24 -1.604705   -1.636146  -1.436364 -1.550845 -0.940163   -1.550842   \n",
       "\n",
       "            ASIAHI_BID  ASIALO_BID  ASIACL_BID  EUROP_BID  ...  ASIA_dBid  \\\n",
       "DATE                                                       ...              \n",
       "2019-06-28   -1.455779   -1.357381   -1.427498  -1.427070  ...  -0.703278   \n",
       "2019-06-27   -1.323379   -1.324542   -1.263411  -1.254421  ...   0.093774   \n",
       "2019-06-26   -1.592316   -1.550310   -1.501337  -1.492841  ...  -0.238331   \n",
       "2019-06-25   -1.633691   -1.677562   -1.677731  -1.764146  ...   0.459090   \n",
       "2019-06-24   -1.600591   -1.476423   -1.530052  -1.513394  ...  -0.902541   \n",
       "\n",
       "            EUR_dBid       OTC  AMER_OTC  ASIA_OTC   EUR_OTC        FT  \\\n",
       "DATE                                                                     \n",
       "2019-06-28 -1.054196       NaN       NaN       NaN       NaN  0.552453   \n",
       "2019-06-27 -0.332944  0.071864  0.071864 -0.231369 -0.337620 -0.123834   \n",
       "2019-06-26 -0.628002  0.147874  0.147874  1.387019  0.345029  0.240321   \n",
       "2019-06-25 -0.824707  1.196813  1.196813  0.270332  1.190921  0.500431   \n",
       "2019-06-24 -0.955843 -0.201772 -0.201772 -0.587414 -0.782826 -0.045800   \n",
       "\n",
       "             AMER_FT   ASIA_FT    EUR_FT  \n",
       "DATE                                      \n",
       "2019-06-28  0.552453 -0.437472  0.506419  \n",
       "2019-06-27 -0.123834  0.822916 -0.879180  \n",
       "2019-06-26  0.240321  0.885935  0.378123  \n",
       "2019-06-25  0.500431 -0.815588  0.224167  \n",
       "2019-06-24 -0.045800  0.003664 -0.212040  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop Ask\n",
    "df = df.drop(columns=['ASK','MID_PRICE','OPEN_ASK','ASK_LOW_1','ASK_HIGH_1'])\n",
    "\n",
    "# L2 Norm\n",
    "mu = df.mean()\n",
    "sig = df.std()\n",
    "df = (df-mu)/sig\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "\n",
    "dataset['GENERAL'] = df[['BID_HIGH_1','BID_LOW_1','NUM_BIDS','dBid','OTC','FT','OPEN_BID','BID']].bfill().values\n",
    "\n",
    "dataset['AMERICA'] = df[['AMERHI_BID','AMERLO_BID','NUM_BIDS','AMER_dBid','AMER_OTC','AMER_FT','AMEROP_BID','AMERCL_BID']].bfill().values\n",
    "\n",
    "dataset['ASIA'] =  df[['ASIAHI_BID','ASIALO_BID','NUM_BIDS','ASIA_dBid','ASIA_OTC','ASIA_FT','ASIAOP_BID','ASIACL_BID']].bfill().values\n",
    "\n",
    "dataset['EUROPE'] =  df[['EURHI_BID','EURLO_BID','NUM_BIDS','EUR_dBid','EUR_OTC','EUR_FT','EUROP_BID','EURCL_BID']].bfill().values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plottable = df[['BID_HIGH_1','BID_LOW_1','NUM_BIDS','dBid','OTC','FT','OPEN_BID','BID']]\n",
    "# Warning: Performance Heavy!\n",
    "# plt.figure(figsize=(30,30))\n",
    "# sns.pairplot(plottable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(14,12))\n",
    "# sns.heatmap(plottable.astype(float).corr(),linewidths=0.1,vmax=1.0, \n",
    "#             square=True, cmap=plt.cm.RdBu, linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def multivariate_data(dataset, target, start_index, end_index, history_size,\n",
    "                      target_size, step, single_step=False):\n",
    "  data = []\n",
    "  labels = []\n",
    "\n",
    "  start_index = start_index + history_size\n",
    "  if end_index is None:\n",
    "    end_index = len(dataset) - target_size\n",
    "\n",
    "  for i in range(start_index, end_index):\n",
    "    indices = range(i-history_size, i, step)\n",
    "    data.append(dataset[indices])\n",
    "\n",
    "    if single_step:\n",
    "      labels.append(target[i+target_size])\n",
    "    else:\n",
    "      labels.append(target[i:i+target_size])\n",
    "\n",
    "  return np.array(data), np.array(labels)\n",
    "\n",
    "\n",
    "\n",
    "def create_time_steps(length):\n",
    "  time_steps = []\n",
    "  for i in range(-length, 0, 1):\n",
    "    time_steps.append(i)\n",
    "  return time_steps\n",
    "\n",
    "\n",
    "\n",
    "def multi_step_plot(history, true_future, prediction):\n",
    "  plt.figure(figsize=(12, 6))\n",
    "  num_in = create_time_steps(len(history))\n",
    "  num_out = len(true_future)\n",
    "\n",
    "  plt.plot(num_in, np.array(history[:, 1]), label='History')\n",
    "  plt.plot(np.arange(num_out)/STEP, np.array(true_future), 'bo',\n",
    "           label='True Future')\n",
    "  if prediction.any():\n",
    "    plt.plot(np.arange(num_out)/STEP, np.array(prediction), 'ro',\n",
    "             label='Predicted Future')\n",
    "  plt.legend(loc='upper left')\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def plot_train_history(history, title):\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  epochs = range(len(loss))\n",
    "\n",
    "  plt.figure()\n",
    "\n",
    "  plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "  plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "  plt.title(title)\n",
    "  plt.legend()\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single window of past history : (60, 8)\n",
      "\n",
      " Target temperature to predict : (1,)\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters (TODO: Grid Search Tuningï¼Œ Fix Underfitting)\n",
    "# 60:20:20 Split (90:5:5 split for GridSearch)\n",
    "TRAIN_SPLIT=int(0.90*df.shape[0])\n",
    "# For multivariate_data function\n",
    "PAST_HISTORY = 60\n",
    "FUTURE_TARGET = 1\n",
    "STEP = 1\n",
    "# For LSTM Model (Don't change this unless we have more data!)\n",
    "BATCH_SIZE = 20\n",
    "BUFFER_SIZE = 4096\n",
    "# For fitting the model\n",
    "EPOCHS=100\n",
    "EVALUATION_INTERVAL=100\n",
    "VALIDATION_STEPS= 50\n",
    "\n",
    "\n",
    "#Define Variables\n",
    "x_train_multi = np.zeros(shape=(0,PAST_HISTORY,8))\n",
    "y_train_multi = np.zeros(shape=(0,FUTURE_TARGET,))\n",
    "x_val_multi = np.zeros(shape=(0,PAST_HISTORY,8))\n",
    "y_val_multi = np.zeros(shape=(0,FUTURE_TARGET,))\n",
    "\n",
    "\n",
    "#NEED HELP: CONCATENATE REPEATABLE DATASETS INSTEAD OF DATASETS\n",
    "for data in dataset:\n",
    "\n",
    "    x_train_multi_temp, y_train_multi_temp = multivariate_data(dataset[data], dataset[data][:, 0], 0,\n",
    "                                                     TRAIN_SPLIT, PAST_HISTORY,\n",
    "                                                     FUTURE_TARGET, STEP)\n",
    "    \n",
    "    x_val_multi_temp, y_val_multi_temp = multivariate_data(dataset[data], dataset[data][:, 0],\n",
    "                                                 TRAIN_SPLIT, None, PAST_HISTORY,\n",
    "                                                 FUTURE_TARGET, STEP)\n",
    "    \n",
    "    x_train_multi = np.concatenate((x_train_multi, x_train_multi_temp), axis=0)\n",
    "    y_train_multi = np.concatenate((y_train_multi, y_train_multi_temp), axis=0)\n",
    "    x_val_multi = np.concatenate((x_val_multi, x_val_multi_temp), axis=0)\n",
    "    y_val_multi = np.concatenate((y_val_multi, y_val_multi_temp), axis=0)\n",
    "    \n",
    "    \n",
    "print ('Single window of past history : {}'.format(x_train_multi[0].shape))\n",
    "print ('\\n Target temperature to predict : {}'.format(y_train_multi[0].shape))\n",
    "\n",
    "train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n",
    "train_data_multi = train_data_multi.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n",
    "val_data_multi = val_data_multi.batch(BATCH_SIZE).repeat()\n",
    "\n",
    "# Generated Samples\n",
    "# for x, y in train_data_multi.take(3):\n",
    "#   multi_step_plot(x[0], y[0], np.array([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM Model\n",
    "\n",
    "def make_model(lstm1_nodes, lstm2_nodes, lstm3_nodes, dropout_percentage= 0.5):\n",
    "    multi_step_model = tf.keras.models.Sequential()\n",
    "    multi_step_model.add(tf.keras.layers.LSTM(lstm1_nodes, return_sequences=True, input_shape=x_train_multi.shape[-2:]))\n",
    "    multi_step_model.add(tf.keras.layers.PReLU())\n",
    "    multi_step_model.add(tf.keras.layers.Dropout(dropout_percentage))\n",
    "    multi_step_model.add(tf.keras.layers.LSTM(lstm2_nodes, return_sequences=True))\n",
    "    multi_step_model.add(tf.keras.layers.PReLU())\n",
    "    multi_step_model.add(tf.keras.layers.Dropout(dropout_percentage))\n",
    "    multi_step_model.add(tf.keras.layers.LSTM(lstm3_nodes, activation='relu'))\n",
    "    multi_step_model.add(tf.keras.layers.Dense(FUTURE_TARGET))\n",
    "\n",
    "    multi_step_model.compile(optimizer=tf.keras.optimizers.Adam(), loss='mae', metrics=['accuracy'])\n",
    "    return multi_step_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1504 samples\n",
      "Epoch 1/20\n",
      "1504/1504 [==============================] - 7s 5ms/sample - loss: 553.9714 - accuracy: 6.6489e-04\n",
      "Epoch 2/20\n",
      " 420/1504 [=======>......................] - ETA: 2s - loss: 521.9909 - accuracy: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "params= {'lstm1_nodes':[2**x for x in range(4,8)],\n",
    "         'lstm2_nodes':[2**x for x in range(3,7)],\n",
    "         'lstm3_nodes':[2**x for x in range(2,6)],\n",
    "#           'dropout_percentage':[0.2],\n",
    "#           'batch_size':[20],\n",
    "#          'epochs':[20],\n",
    "#          'steps_per_epoch':[200]\n",
    "        }\n",
    "\n",
    "clf = KerasClassifier(make_model, batch_size=20, dropout_percentage=0.2, epochs=20)\n",
    "validator = GridSearchCV(clf,\n",
    "                         param_grid=params,\n",
    "                         scoring='neg_mean_absolute_error',\n",
    "                         n_jobs=1,cv=3, error_score=np.nan,verbose=0)\n",
    "validator.fit(x_train_multi, y_train_multi)\n",
    "\n",
    "print('The parameters of the best model are: ')\n",
    "print(validator.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validator.best_estimator_ returns sklearn-wrapped version of best model.\n",
    "# validator.best_estimator_.model returns the (unwrapped) keras model\n",
    "best_model = validator.best_estimator_.model\n",
    "metric_names = best_model.metrics_names\n",
    "metric_values = best_model.evaluate(x_test, y_test)\n",
    "for metric, value in zip(metric_names, metric_values):\n",
    "    print(metric, ': ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15)\n",
    "\n",
    "# multi_step_history = multi_step_model.fit(train_data_multi, epochs=EPOCHS,\n",
    "#                                           steps_per_epoch=EVALUATION_INTERVAL,\n",
    "#                                           validation_data=val_data_multi,\n",
    "#                                           validation_steps=VALIDATION_STEPS, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_train_history(multi_step_history, 'Multi-Step Training and validation loss')\n",
    "\n",
    "# # Predicted Samples\n",
    "# for x, y in val_data_multi.take(3):\n",
    "#   multi_step_plot(x[0], y[0], multi_step_model.predict(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
